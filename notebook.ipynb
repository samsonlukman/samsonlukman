{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Embedding, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Embedding, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Embedding, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = 'archive.zip'\n",
    "\n",
    "# Specify the target directory for extraction\n",
    "base_directory = ''\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all contents to the target directory\n",
    "    zip_ref.extractall(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    image_folder = 'images'\n",
    "    csv_file = 'styles.csv'\n",
    "\n",
    "    sneakers_folder = 'sneakers'\n",
    "\n",
    "    # Create the sneakers folder if it doesn't exist\n",
    "    if not os.path.exists(sneakers_folder):\n",
    "        os.mkdir(sneakers_folder)\n",
    "\n",
    "    try:\n",
    "        # Read the styles.csv file using pandas and skip bad lines\n",
    "        df = pd.read_csv('styles.csv', on_bad_lines='skip')\n",
    "    except pd.errors.ParserError as ex:\n",
    "        print(f\"Error parsing CSV file: {ex}\")\n",
    "        df = pd.read_csv(csv_file, on_bad_lines= 'skip')\n",
    "\n",
    "    # Filter images with 'Casual Shoes' or 'Sport Shoes' in the 'articleType' column\n",
    "    sneaker_images = df[df['articleType'].isin(['Casual Shoes', 'Sports Shoes'])]\n",
    "\n",
    "    # Copy selected images to the 'sneakers' folder\n",
    "    for index, row in sneaker_images.iterrows():\n",
    "        image_id = str(row['id']) + \".jpg\"  # Assuming the image filenames include \".jpg\"\n",
    "        source_path = os.path.join(image_folder, image_id)\n",
    "        destination_path = os.path.join(sneakers_folder, image_id)\n",
    "\n",
    "        # Check if the image file exists before copying\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.copy(source_path, destination_path)\n",
    "\n",
    "    print(\"Sneaker images copied to the 'sneakers' folder.\")\n",
    "except Exception as ex:\n",
    "    print(f\"An error occurred: {ex}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneakers = 'sneakers'\n",
    "image_files = glob.glob(os.path.join(sneakers, '*.jpg'))\n",
    "\n",
    "# Get the count of image files\n",
    "num_images = len(image_files)\n",
    "\n",
    "print(f'This is the total number of images in the folder: {num_images}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load styles data\n",
    "styles_df = pd.read_csv('styles.csv', on_bad_lines='skip')\n",
    "\n",
    "# Map gender labels to integers\n",
    "gender_mapping = {'Boys': 1, 'Girls': 2, 'Women': 3, 'Men': 4, 'Unisex': 5}\n",
    "styles_df['gender'] = styles_df['gender'].map(gender_mapping)\n",
    "\n",
    "# Define hyperparameters\n",
    "z_dim = 100\n",
    "label_dim = len(gender_mapping)\n",
    "image_shape = (128, 128, 3)\n",
    "\n",
    "# Load and preprocess images\n",
    "sneakers_folder = 'sneakers'\n",
    "image_width = 128\n",
    "image_height = 128\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for root, _, files in os.walk(sneakers_folder):\n",
    "    for file in files:\n",
    "        image_path = os.path.join(root, file)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (image_width, image_height))\n",
    "        image = image / 255.0\n",
    "        label = int(os.path.splitext(os.path.basename(file))[0])\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Visualize the data (example for the first 9 images)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i])\n",
    "    ax.set_title(f'Label: {labels[i]}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the frequency of each label in the training set\n",
    "label_counts = styles_df['gender'].value_counts().reset_index()\n",
    "label_counts.columns = ['Gender', 'Frequency']\n",
    "\n",
    "# Create a bar chart using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Gender', y='Frequency', data=label_counts)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Gender Distribution in the Styles Dataset')\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100  # Dimension of the random noise vector\n",
    "label_dim = 10  # Number of unique labels\n",
    "image_shape = (128, 128, 3)  # Adjust to match your image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(z_dim, label_dim, image_shape):\n",
    "    # Input for random noise vector\n",
    "    z = Input(shape=(z_dim,))\n",
    "    # Input for label\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    # Embedding layer for labels\n",
    "    label_embedding = Flatten()(Embedding(label_dim, z_dim)(label))\n",
    "\n",
    "    # Concatenate noise and label inputs\n",
    "    combined = concatenate([z, label_embedding])\n",
    "\n",
    "    # Fully connected layers to generate an image\n",
    "    x = Dense(128, input_dim=z_dim + label_dim)(combined)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(np.prod(image_shape), activation='tanh')(x)\n",
    "    x = Reshape(image_shape)(x)\n",
    "\n",
    "    return Model([z, label], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape, label_dim):\n",
    "    # Input for the image\n",
    "    img = Input(shape=image_shape)\n",
    "    # Input for label\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    # Embedding layer for labels\n",
    "    label_embedding = Flatten()(Embedding(label_dim, np.prod(image_shape))(label))\n",
    "\n",
    "    # Flatten the image\n",
    "    img_flatten = Flatten()(img)\n",
    "\n",
    "    # Concatenate image and label inputs\n",
    "    combined = concatenate([img_flatten, label_embedding])\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Dense(128)(combined)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model([img, label], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles_df = pd.read_csv('styles.csv', on_bad_lines='skip')\n",
    "\n",
    "\n",
    "# Use the 'gender' column from the dataset as labels\n",
    "labels = styles_df['gender']\n",
    "# Map string labels to integers\n",
    "label_mapping = {'Boys': 1, 'Girls': 2, 'Women': 3, 'Men': 4, 'Unisex': 5}\n",
    "encoded_labels = labels.map(label_mapping)\n",
    "\n",
    "\n",
    "# Check encoded_labels\n",
    "print(encoded_labels)\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "z_dim = 100  # Dimension of the random noise vector\n",
    "label_dim = 6 # Number of unique labels\n",
    "image_shape = (128, 128, 3)\n",
    "\n",
    "\n",
    "# Check X_train shape\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator(z_dim, label_dim, image_shape)\n",
    "\n",
    "\n",
    "# Build the discriminator\n",
    "discriminator = build_discriminator(image_shape, label_dim)\n",
    "\n",
    "\n",
    "# GAN input layers\n",
    "gan_input_z = Input(shape=(z_dim,))\n",
    "gan_input_label = Input(shape=(1,), dtype='int32')  # Ensure labels are of integer type\n",
    "\n",
    "\n",
    "# Generate images from the generator\n",
    "generated_image = generator([gan_input_z, gan_input_label])\n",
    "\n",
    "\n",
    "# Ensure that the discriminator is not trainable during GAN training\n",
    "discriminator.trainable = False\n",
    "\n",
    "\n",
    "# Get the validity of generated images\n",
    "validity = discriminator([generated_image, gan_input_label])\n",
    "\n",
    "\n",
    "# Create the GAN model\n",
    "gan = Model([gan_input_z, gan_input_label], validity)\n",
    "\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Compile the GAN\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and number of epochs\n",
    "import numpy as np\n",
    "\n",
    "# Define the batch size and number of epochs\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "   # Determine the current batch size based on the available data\n",
    "   current_batch_size = min(batch_size, X_train.shape[0])\n",
    "\n",
    "\n",
    "   # Generate random noise vectors for the generator\n",
    "   noise = np.random.normal(0, 1, size=(current_batch_size, z_dim))\n",
    "\n",
    "\n",
    "   # Generate random labels for the generated images\n",
    "   generated_labels = np.random.choice(label_dim, current_batch_size)\n",
    "\n",
    "\n",
    "   # Generate fake images from the generator\n",
    "   generated_images = generator.predict([noise, generated_labels])\n",
    "\n",
    "\n",
    "   # Select a random batch of real images\n",
    "   indices = np.random.choice(X_train.shape[0], current_batch_size, replace=False)\n",
    "   real_images = X_train[indices]\n",
    "   real_labels = encoded_labels[indices]\n",
    "\n",
    "\n",
    "   # Create target labels for the discriminator\n",
    "   valid = np.ones((current_batch_size, 1))\n",
    "   fake = np.zeros((current_batch_size, 1))\n",
    "   d_loss_real = discriminator.train_on_batch([real_images, real_labels], valid)\n",
    "   d_loss_fake = discriminator.train_on_batch([generated_images, generated_labels], fake)\n",
    "   d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "   # Train the GAN (generator) by trying to generate valid images\n",
    "   g_loss = gan.train_on_batch([noise, generated_labels], valid)\n",
    "\n",
    "\n",
    "   # Print progress\n",
    "   print(f\"Epoch {epoch}/{epochs}, D Loss: {d_loss[0]}, G Loss: {g_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of images you want to generate\n",
    "num_images_to_generate = 10\n",
    "\n",
    "# Generate random noise vectors for the generator\n",
    "noise = np.random.normal(0, 1, size=(num_images_to_generate, z_dim))\n",
    "\n",
    "# Generate random labels for the generated images\n",
    "generated_labels = np.random.choice(label_dim, num_images_to_generate)\n",
    "\n",
    "# Generate fake images from the generator\n",
    "generated_images = generator.predict([noise, generated_labels])\n",
    "\n",
    "# Visualize the generated images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the generated images\n",
    "fig, axes = plt.subplots(1, num_images_to_generate, figsize=(15, 15))\n",
    "for i in range(num_images_to_generate):\n",
    "    axes[i].imshow((generated_images[i] + 1) / 2)\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
